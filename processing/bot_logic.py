# -*- coding: utf-8 -*- 

import os
import shutil
from concurrent.futures import ThreadPoolExecutor, as_completed
from queue import Queue


from pathlib import Path
import logging
import contextlib


import subprocess
from moviepy.editor import (
    VideoFileClip,
    CompositeVideoClip, ImageClip,
    vfx, concatenate_videoclips
)
import json
from faster_whisper import WhisperModel
from processing.transcription import get_transcript_segments_and_file, get_audio_duration, get_whisper_model
from processing.subtitles import create_ass_subtitles, get_subtitle_items
from config import VIDEO_MAP, MAX_SHORTS_PER_VIDEO, MIN_SHORT_DURATION, MAX_SHORT_DURATION
from .download import download_video_segment, get_video_duration, get_video_heatmap
from .layouts import _build_video_canvas
from .gpt import get_highlights_from_gpt, get_random_highlights
from utils import to_seconds, format_seconds_to_hhmmss
from localization import get_translation



logger = logging.getLogger(__name__)


def get_unique_output_dir(base="output"):
    n = 1
    while True:
        out_dir = f"{base}{n}"
        if not Path(out_dir).exists():
            Path(out_dir).mkdir(parents=True)
            return out_dir
        n += 1

@contextlib.contextmanager
def temporary_directory(delete: bool = True):
    """Context manager for creating and cleaning up a temporary directory."""
    temp_dir = get_unique_output_dir()
    try:
        yield Path(temp_dir)
    finally:
        if delete:
            shutil.rmtree(temp_dir)
            print(f"üóëÔ∏è –ü–∞–ø–∫–∞ {temp_dir} —É–¥–∞–ª–µ–Ω–∞.")

def transcribe_audio(url: str, out_dir: Path, lang: str):
    """
    Downloads pre-existing subtitles from YouTube.
    If it fails, it raises an exception, and the main workflow will fall back to random clips.
    Returns None if transcription fails.
    """
    print("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –≤–∏–¥–µ–æ...")
    try:
        transcript_segments, lang_code = get_transcript_segments_and_file(
            url, out_dir=out_dir, force_whisper=False
        )
        if not transcript_segments:
            raise ValueError("No transcript segments found.")
        # This workflow no longer downloads the full audio, so return None for audio_only
        return transcript_segments, lang_code, None
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—É–±—Ç–∏—Ç—Ä—ã (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º): {e}")
        return None, None, None


def get_highlights(url: str, out_dir: Path, audio_path: Path, shorts_number: any, video_duration: float):
    print("–ò—â–µ–º –≤–∏—Ä–∞–ª—å–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã...")
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º get_audio_duration —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª —Ä–µ–∞–ª—å–Ω–æ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    duration = video_duration if video_duration else (get_audio_duration(audio_path) if audio_path and audio_path.exists() else 0)
    
    shorts_timecodes = []

    # 1. Heatmap Strategy
    try:
        print("–ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å Heatmap...")
        heatmap = get_video_heatmap(url)
        print(heatmap)
        if heatmap:
            count = 3
            if shorts_number == 'auto':
                if duration < 600: count = 3
                elif duration < 1200: count = 5
                elif duration < 2400: count = 8
                else: count = 10
            else:
                try:
                    count = int(shorts_number)
                except:
                    count = 3
            
            count = min(count, MAX_SHORTS_PER_VIDEO)
            
            window_size = float(MAX_SHORT_DURATION)
            step = 5.0
            candidates = []
            curr = 0.0
            
            while curr + window_size <= duration:
                w_start = curr
                w_end = curr + window_size
                score = 0.0
                for point in heatmap:
                    p_start = point.get('start_time', 0)
                    p_end = point.get('end_time', 0)
                    val = point.get('value', 0)
                    overlap = max(0, min(w_end, p_end) - max(w_start, p_start))
                    score += overlap * val
                candidates.append({'start': w_start, 'end': w_end, 'score': score})
                curr += step
            
            candidates.sort(key=lambda x: x['score'], reverse=True)
            selected = []
            for cand in candidates:
                if len(selected) >= count: break
                if not any(not (cand['end'] <= s['start'] or cand['start'] >= s['end']) for s in selected):
                    selected.append(cand)
            
            if selected:
                for s in selected:
                    avg_val = s['score'] / window_size
                    v_score = max(1, min(10, int(round(avg_val * 10)*2)))  # Scale to 1-10 and boost by 1.5x
                    shorts_timecodes.append({
                        "start": format_seconds_to_hhmmss(s['start']),
                        "end": format_seconds_to_hhmmss(s['end']),
                        "hook": "",
                        "virality_score": v_score
                    })
                print(f"Heatmap –≤–µ—Ä–Ω—É–ª {len(shorts_timecodes)} –æ—Ç—Ä–µ–∑–∫–æ–≤.")
                return shorts_timecodes
    except Exception as e:
        logger.warning(f"Heatmap processing failed: {e}")

    # 2. GPT Strategy
    print("–ò—â–µ–º —Å–º—ã—Å–ª–æ–≤—ã–µ –∫—É—Å–∫–∏ —á–µ—Ä–µ–∑ GPT...")
    captions_file = out_dir / "captions.txt"
    try:
        shorts_timecodes = get_highlights_from_gpt(out_dir / "captions.txt", duration, shorts_number=shorts_number)
        if not captions_file.exists():
            raise FileNotFoundError("–§–∞–π–ª —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º GPT.")
            
        shorts_timecodes = get_highlights_from_gpt(captions_file, duration, shorts_number=shorts_number)
        if not shorts_timecodes:
            # –í—ã–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫—É, —á—Ç–æ–±—ã –ø–µ—Ä–µ–π—Ç–∏ –≤ –±–ª–æ–∫ except –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å fallback
            raise ValueError("GPT –Ω–µ –≤–µ—Ä–Ω—É–ª —Ç–∞–π–º–∫–æ–¥—ã")
        return shorts_timecodes
    except Exception as e:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ö–∞–π–ª–∞–π—Ç—ã –æ—Ç GPT (%s), –ø–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª—É—á–∞–π–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.", e)
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ö–∞–π–ª–∞–π—Ç—ã –æ—Ç GPT ({e}), –ø–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª—É—á–∞–π–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.")
        
        # 3. Random Fallback
        try:
            shorts_timecodes_raw = get_random_highlights(shorts_number, duration)
            if not shorts_timecodes_raw:
                print("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–ª—É—á–∞–π–Ω—ã–µ –æ—Ç—Ä–µ–∑–∫–∏.")
                return None
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–µ–∫—É–Ω–¥—ã –≤ —Ñ–æ—Ä–º–∞—Ç HH:MM:SS
            for it in shorts_timecodes_raw:
                shorts_timecodes.append({
                    "start": format_seconds_to_hhmmss(float(it["start"])),
                    "end":   format_seconds_to_hhmmss(float(it["end"])),
                    "hook":  it["hook"],
                    "virality_score": it.get("virality_score", 5)
                })
            return shorts_timecodes
        except Exception as fallback_e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–ª—É—á–∞–π–Ω—ã—Ö –æ—Ç—Ä–µ–∑–∫–æ–≤: {fallback_e}")
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–ª—É—á–∞–π–Ω—ã–µ –æ—Ç—Ä–µ–∑–∫–∏ –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ñ–æ–ª–±—ç–∫–∞: %s", fallback_e)
            return None

    return None

def create_clips(config, url, audio_only, shorts_to_process, transcript_segments, out_dir, send_video_callback):
    render_futures = process_video_clips(config, url, audio_only, shorts_to_process, transcript_segments, out_dir, send_video_callback)
    
    successful_sends = 0
    if render_futures:
        for render_future in render_futures:
            try:
                # –ü–µ—Ä–≤—ã–π .result() –æ–∂–∏–¥–∞–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ _render_clip_from_segment.
                # –û–Ω –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç future, —Å–æ–∑–¥–∞–Ω–Ω—ã–π run_coroutine_threadsafe.
                send_future = render_future.result()
                
                if send_future:
                    # –í—Ç–æ—Ä–æ–π .result() –æ–∂–∏–¥–∞–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ—Ä—É—Ç–∏–Ω—ã send_video.
                    # –≠—Ç–æ –±–ª–æ–∫–∏—Ä—É—é—â–∏–π –≤—ã–∑–æ–≤, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≥–æ–Ω–∫–∏.
                    # –î–æ–±–∞–≤–ª–µ–Ω —Ç–∞–π–º–∞—É—Ç, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –≤–µ—á–Ω–æ–≥–æ –∑–∞–≤–∏—Å–∞–Ω–∏—è.
                    success = send_future.result(timeout=600) 
                    if success:
                        successful_sends += 1
            except Exception as e:
                logger.error("Future –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤–∏–¥–µ–æ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: %s", e, exc_info=True)

    return successful_sends

def main(url, config, status_callback=None, send_video_callback=None, deleteOutputAfterSending=False):
    config['bottom_video_path'] = VIDEO_MAP.get(config['bottom_video'])
    lang = config.get('lang', 'ru')
    platform = config.get('platform', 'youtube')
    shorts_number = config.get('shorts_number', 'auto')

    with temporary_directory(delete=deleteOutputAfterSending) as out_dir:
        if platform == 'twitch':
            return main_twitch(url, config, out_dir, status_callback, send_video_callback)
        
        # YouTube workflow
        if status_callback:
            status_callback(get_translation(lang, "analyzing_video"))
        
        # 1. –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –≤—Å–µ–≥–æ)
        video_duration = get_video_duration(url)
        if not video_duration:
            logger.error(f"Failed to get video duration for {url}")
            return 0, 0

        # 2. –ü—Ä–æ–±—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –Ω—É–∂–Ω–æ –¥–ª—è GPT –∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤)
        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏—Ç—Å—è - –≤–µ—Ä–Ω–µ—Ç None, –∏ –º—ã –ø—Ä–æ—Å—Ç–æ –Ω–µ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPT/—Å—É–±—Ç–∏—Ç—Ä—ã
        transcript_segments, _, audio_only = transcribe_audio(url, out_dir, lang)

        # 3. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ö–∞–π–ª–∞–π—Ç—ã (Heatmap -> GPT -> Random)
        shorts_timecodes = get_highlights(url, out_dir, audio_only, shorts_number, video_duration)
        
        if not shorts_timecodes:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–∞–π–º–∫–æ–¥—ã –Ω–∏ –æ–¥–Ω–∏–º –∏–∑ –º–µ—Ç–æ–¥–æ–≤.")
            if status_callback:
                status_callback(get_translation(lang, "gpt_highlights_error"))
            return 0, 0
            
        shorts_timecodes.sort(key=lambda x: x.get('virality_score', 0), reverse=True)

        num_to_process = len(shorts_timecodes)
        shorts_to_process = shorts_timecodes[:num_to_process]
        extra_found = 0

        if status_callback:
            status_callback(get_translation(lang, "clips_found").format(shorts_timecodes_len=len(shorts_timecodes), num_to_process=num_to_process))
        print(f"–ù–∞–π–¥–µ–Ω–Ω—ã–µ –æ—Ç—Ä–µ–∑–∫–∏ –¥–ª—è —à–æ—Ä—Ç—Å–æ–≤ ({len(shorts_timecodes)}):", shorts_timecodes)

        # 4. –°–æ–∑–¥–∞–µ–º –∫–ª–∏–ø—ã
        successful_sends = create_clips(config, url, audio_only, shorts_to_process, transcript_segments, out_dir, send_video_callback)

        if audio_only and os.path.exists(audio_only):
            try: os.remove(audio_only)
            except OSError: pass
        
        return successful_sends, extra_found


def handle_random_clips_workflow(url, config, out_dir, status_callback, send_video_callback):
    """
    A workflow for generating clips based on random timestamps.
    Used for Twitch or as a fallback for YouTube.
    """
    lang = config.get('lang', 'ru')
    
    try:
        duration = get_video_duration(url)
        if not duration:
            logger.error(f"yt-dlp did not return a duration for URL {url}, but did not error.")
            return 0, 0
    except Exception as e:
        logger.error(f"FATAL: Failed to get video duration for {url} in fallback workflow. Exception: {e}", exc_info=True)
        return 0, 0
        
    shorts_number = config.get('shorts_number', 'auto')
    try:
        shorts_timecodes_raw = get_random_highlights(shorts_number, duration)
        if not shorts_timecodes_raw:
            raise ValueError("GPT returned no timecodes.")
            
        # Convert seconds to HH:MM:SS format
        shorts_timecodes = []
        for it in shorts_timecodes_raw:
            shorts_timecodes.append({
                "start": format_seconds_to_hhmmss(float(it["start"])),
                "end":   format_seconds_to_hhmmss(float(it["end"])),
                "hook":  it["hook"],
                "virality_score": it.get("virality_score", 5)
            })

        # Sort by virality score
        shorts_timecodes.sort(key=lambda x: x.get('virality_score', 0), reverse=True)

    except Exception as e:
        logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–µ —Ö–∞–π–ª–∞–π—Ç—ã –æ—Ç GPT: {e}")
        if status_callback:
            status_callback(get_translation(lang, "gpt_highlights_error"))
        return 0, 0

    if not shorts_timecodes:
        if status_callback:
            status_callback(get_translation(lang, "gpt_highlights_error"))
        return 0, 0

    num_to_process = len(shorts_timecodes)
    if status_callback:
        status_callback(get_translation(lang, "clips_found").format(shorts_timecodes_len=len(shorts_timecodes), num_to_process=num_to_process))

    # The new orchestrator function handles the rest
    futures = orchestrate_clip_creation(
        config=config,
        url=url,
        shorts_timecodes=shorts_timecodes,
        out_dir=out_dir,
        send_video_callback=send_video_callback,
        audio_path=None,
        full_transcript_segments=None,
        status_callback=status_callback
    )

    successful_sends = 0
    for render_future in futures:
        try:
            # .result() on the render_future waits for _render_clip_from_segment to complete
            # and returns the send_future created by run_coroutine_threadsafe
            send_future = render_future.result()
            
            if send_future:
                # .result() on the send_future waits for the send_video coroutine to finish
                success = send_future.result(timeout=600) 
                if success:
                    successful_sends += 1
        except Exception as e:
            logger.error(f"Future –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤–∏–¥–µ–æ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: {e}", exc_info=True)

    return successful_sends, 0

def main_twitch(url, config, out_dir, status_callback, send_video_callback):
    """Entry point for the Twitch workflow."""
    return handle_random_clips_workflow(url, config, out_dir, status_callback, send_video_callback)


def _render_clip_from_segment(config, segment_video_path, short_info, clip_num, out_dir, audio_path, full_transcript_segments, send_video_callback):
    """
    Handles the rendering of a single video clip from an already downloaded segment.
    """
    final_width = 720
    final_height = 1280
    start_cut = to_seconds(short_info["start"])
    end_cut = to_seconds(short_info["end"])

    main_clip_raw = VideoFileClip(str(segment_video_path))
    
    subtitles_type = config.get('subtitles_type', 'word-by-word')
    
    current_transcript_segments = full_transcript_segments
    
    ass_path = None
    if subtitles_type != 'no_subtitles':
        faster_whisper_model = get_whisper_model()
        
        if current_transcript_segments is None:
            segments, _ = get_transcript_segments_and_file(
                url=None, 
                out_dir=out_dir,
                audio_path=segment_video_path,
                force_whisper=True,
                is_twitch_clip=True
            )
            current_transcript_segments = segments

        if not config.get('capitalize_sentences', True):
            for seg in current_transcript_segments:
                if seg['start'] >= start_cut:
                    text = seg['text']
                    lstripped_text = text.lstrip()
                    if lstripped_text:
                        new_text = lstripped_text[0].lower() + lstripped_text[1:]
                        seg['text'] = new_text
                if seg['start'] > end_cut:
                    break
        
        audio_for_subtitles = segment_video_path if audio_path is None else audio_path
        subtitle_items = get_subtitle_items(
            subtitles_type, current_transcript_segments, audio_for_subtitles, start_cut, end_cut, 
            faster_whisper_model)
        
        ass_path = out_dir / f"short{clip_num}.ass"
        
        video_canvas, subtitle_y_pos, subtitle_width = _build_video_canvas(
            config, main_clip_raw, final_width, final_height
        )
        final_clip = video_canvas

        create_ass_subtitles(
            subtitle_items, str(ass_path), final_width, final_height,
            subtitle_y_pos, subtitle_width, config.get('subtitle_style', 'white'), subtitles_type
        )
    else:
        video_canvas, _, _ = _build_video_canvas(config, main_clip_raw, final_width, final_height)
        final_clip = video_canvas

    if config.get('add_banner'):
        banner_type = config.get('add_banner')
        if banner_type == 'shorts_factory_banner':
            banner_path = 'banner.png'
            if os.path.exists(banner_path):
                banner_clip = (ImageClip(banner_path)
                               .set_duration(final_clip.duration)
                               .resize(width=final_clip.w * 0.4)
                               .set_position(('center', final_clip.h * 0.1)))
                final_clip = CompositeVideoClip([final_clip, banner_clip])
            else:
                logger.warning(f"Banner file not found at {banner_path}")
        elif banner_type == 'getcourse_banner':
            banner_path = 'getcourse_banner_encoded.mp4'
            if os.path.exists(banner_path):
                banner_video = VideoFileClip(banner_path).without_audio()
                banner_video = banner_video.loop(duration=final_clip.duration)
                banner_clip = (banner_video
                               .resize(width=final_clip.w * 0.5) # Half width
                               .set_position(('center', final_clip.h * 0.1))) # Centered horizontally, 10% from top
                final_clip = CompositeVideoClip([final_clip, banner_clip])
            else:
                logger.warning(f"Banner file not found at {banner_path}")

    final_clip = final_clip.set_duration(main_clip_raw.duration)
    output_sub = out_dir / f"short{clip_num}.mp4"

    if ass_path and os.path.exists(ass_path):
        final_clip = final_clip.set_audio(None)
        temp_video_path = out_dir / f"temp_short{clip_num}.mp4"
        final_clip.write_videofile(str(temp_video_path), fps=24, codec="libx264", audio=False)
        
        fonts_dir = "fonts"
        ffmpeg_vf = f"subtitles={str(ass_path)}:fontsdir={fonts_dir}"
        cmd = [
            "ffmpeg", "-i", str(temp_video_path), "-i", str(segment_video_path),
            "-vf", ffmpeg_vf, "-c:v", "libx264", "-preset", "medium", "-crf", "23",
            "-c:a", "aac", "-map", "0:v:0", "-map", "1:a:0", "-y", str(output_sub)
        ]
        try:
            subprocess.run(cmd, check=True, capture_output=True, text=True)
        except subprocess.CalledProcessError as e:
            print(f"Error burning subtitles with ffmpeg: {e.stderr}")
            shutil.copy(temp_video_path, output_sub)
        finally:
            if os.path.exists(temp_video_path): os.remove(temp_video_path)
            if os.path.exists(ass_path): os.remove(ass_path)
    else:
        final_clip = final_clip.set_audio(main_clip_raw.audio)
        final_clip.write_videofile(str(output_sub), fps=24, codec="libx264", audio_codec="aac")
    
    if os.path.exists(segment_video_path):
        os.remove(segment_video_path)

    print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª {output_sub}")
    
    if send_video_callback:
        virality_score = short_info.get("virality_score", None) # Get score, default to None
        return send_video_callback(file_path=output_sub, hook=short_info["hook"], start=short_info["start"], end=short_info["end"], virality_score=virality_score)
    return None

def orchestrate_clip_creation(config, url, shorts_timecodes, out_dir, send_video_callback, audio_path=None, full_transcript_segments=None, status_callback=None):
    """
    Orchestrates the creation of video clips using a producer-consumer pattern.
    Downloads segments sequentially while rendering them sequentially, but overlapping the two phases.
    """
    render_futures = []       # Futures for the rendering tasks
    
    # 1. Define the downloader worker function
    def _download_worker_task(clip_num, short_info):
        start_cut = to_seconds(short_info["start"])
        end_cut = to_seconds(short_info["end"])
        segment_video_path = out_dir / f"segment_{clip_num}.mp4"
        try:
            print(f"Downloading segment {clip_num} ({short_info['start']}-{short_info['end']})...")
            download_video_segment(url, segment_video_path, start_cut, end_cut)
            return clip_num, segment_video_path, short_info
        except Exception as e:
            logger.error(f"Failed to download segment {clip_num} ({start_cut}-{end_cut}): {e}", exc_info=True)
            return clip_num, None, short_info

    # 2. Start the downloader in a single-worker executor
    download_executor = ThreadPoolExecutor(max_workers=1)
    # Submit all download tasks to the downloader executor.
    # They will be executed sequentially by this executor.
    download_submission_futures = [
        download_executor.submit(_download_worker_task, i + 1, short)
        for i, short in enumerate(shorts_timecodes)
    ]

    # 3. Start the renderer in a single-worker executor
    render_executor = ThreadPoolExecutor(max_workers=1)

    download_count = 0
    total_downloads = len(shorts_timecodes)

    # 4. As downloads complete, feed them to the renderer
    for future in as_completed(download_submission_futures):
        clip_num, segment_path, short_info = future.result()
        if segment_path:
            download_count += 1
            print(f"Finished downloading segment {clip_num}. {download_count}/{total_downloads} downloaded.")
            # if status_callback:
            #     lang = config.get('lang', 'ru')
            #     status_callback(get_translation(lang, "downloading_clips").format(current=download_count, total=total_downloads))
            
            # Submit rendering task for this downloaded segment
            print(f"Submitting clip #{clip_num} for rendering...")
            render_future = render_executor.submit(
                _render_clip_from_segment,
                config=config,
                segment_video_path=segment_path,
                short_info=short_info,
                clip_num=clip_num,
                out_dir=out_dir,
                audio_path=audio_path,
                full_transcript_segments=full_transcript_segments,
                send_video_callback=send_video_callback
            )
            render_futures.append(render_future)
        else:
            print(f"Skipping rendering for clip #{clip_num} due to failed download.")
            logger.warning(f"Clip #{clip_num} download failed, skipping rendering.")

    # Shut down executors
    download_executor.shutdown(wait=True)
    render_executor.shutdown(wait=True)
    
    # Return futures for the send_video_callback results
    return render_futures


def process_video_clips(config, url, audio_path, shorts_timecodes, transcript_segments, out_dir, send_video_callback=None):
    return orchestrate_clip_creation(
        config=config,
        url=url,
        shorts_timecodes=shorts_timecodes,
        out_dir=out_dir,
        send_video_callback=send_video_callback,
        audio_path=audio_path,
        full_transcript_segments=transcript_segments
    )

if __name__ == "__main__":
    url = "https://youtu.be/4_3VXLK_K_A?si=GVZ3IySlOPK09Ohc"
    # ================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ==================
    config = {
        # –û–ø—Ü–∏–∏: 'white', 'yellow'
        'subtitle_style': 'yellow',
        
        # –û–ø—Ü–∏–∏: 'gta', 'minecraft' –∏–ª–∏ None –¥–ª—è —á–µ—Ä–Ω–æ–≥–æ —Ñ–æ–Ω–∞
        'bottom_video': 'minecraft', 
        
        # –û–ø—Ü–∏–∏: 'square_top_brainrot_bottom', 'square_center', 'full_top_brainrot_bottom', 'full_center', 'face_track_9_16'
        'layout': 'square_center',

        # –û–ø—Ü–∏–∏: 'word-by-word', 'phrases', None
        'subtitles_type': None,

        # –û–ø—Ü–∏–∏: True, False
        'capitalize_sentences': True
    }
    # ================================================
    shorts = main(url, config)
